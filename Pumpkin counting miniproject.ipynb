{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Colour based segmentation\n",
    "This part consists of using colour based information\n",
    "to segment individual images from a pumpkin field.\n",
    "The segmented images should end up having a black\n",
    "background with smaller white objects on top."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1.1\n",
    "Annotate some pumpkins in a test image and extract information about the average pumpkin colour\n",
    "in the annotated pixels. Calculate both mean value\n",
    "and standard variation. Use the following two colour\n",
    "spaces: RGB and CieLAB. Finally try to visualise\n",
    "the distribution of colour values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean color values of the annotated pixels:\n",
      " [[ 46.41416428]\n",
      " [150.11533625]\n",
      " [230.19802827]]\n",
      "Standard deviation of color values of the annotated pixels:\n",
      " [[21.71128969]\n",
      " [16.11388805]\n",
      " [17.11028936]]\n",
      "Covariance matrix of color values of the annotated pixels:\n",
      " [[471.40381144 205.71747089 131.0308569 ]\n",
      " [205.71747089 259.6704494  231.02876867]\n",
      " [131.0308569  231.02876867 292.77672851]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_true = cv2.imread(\"Output/1/1/BGR/Ground_true_EB-02-660_0594_0326.JPG\")\n",
    "\n",
    "img = cv2.imread('Images/EB-02-660_0594_0326.JPG')\n",
    "cv2.imwrite(\"Output/1/1/BGR/img.png\", img)\n",
    "\n",
    "# lower bound and upper bound for red color\n",
    "lower_bound = np.array([0, 0, 250])\n",
    "upper_bound = np.array([0, 0, 255])\n",
    "\n",
    "# Find the colors within the boundaries\n",
    "mask = cv2.inRange(img_true, lower_bound, upper_bound)\n",
    "cv2.imwrite(\"output/1/1/BGR/mask.png\", mask)\n",
    "mask_pixels = np.reshape(mask, (-1))\n",
    "\n",
    "img = cv2.bitwise_and(img, img, mask=mask)\n",
    "pixels = np.reshape(img, (-1, 3))\n",
    "cv2.imwrite(\"output/1/1/BGR/RGB.png\", img)\n",
    "\n",
    "# Mean and standard deviation\n",
    "mean, std = cv2.meanStdDev(img, mask=mask)\n",
    "print(f\"Mean color values of the annotated pixels:\\n {mean}\")\n",
    "print(f\"Standard deviation of color values of the annotated pixels:\\n {std}\")\n",
    "\n",
    "# Covariance\n",
    "cov = np.cov(pixels.transpose(), aweights=mask_pixels)\n",
    "print(f\"Covariance matrix of color values of the annotated pixels:\\n {cov}\")\n",
    "\n",
    "# Save the parameters\n",
    "np.savetxt(\"Output/1/1/BGR/lower.txt\", mean-std, delimiter=' ', fmt='%1.4f')\n",
    "np.savetxt(\"Output/1/1/BGR/upper.txt\", mean+std, delimiter=' ', fmt='%1.4f')\n",
    "np.savetxt(\"Output/1/1/BGR/mean.txt\", mean, delimiter=' ', fmt='%1.4f')\n",
    "\n",
    "\n",
    "# Test the output\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "mask = cv2.inRange(img, mean-std, mean+std)\n",
    "img_test = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite(\"Output/1/1/BGR/test.png\", img_test)\n",
    "\n",
    "# Show the histogram\n",
    "colors = ['b', 'g', 'r']\n",
    "for dim in range(img_test.ndim):\n",
    "    data = np.reshape(img_test[:, :, dim], (-1))\n",
    "    plt.hist(data[data != 0], bins=255, color=colors[dim], alpha=0.5)\n",
    "plt.savefig(\"Output/1/1/BGR/histogram.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CieLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean color values of the annotated pixels:\n",
      " [[175.31995372]\n",
      " [150.28308435]\n",
      " [190.01353051]]\n",
      "Standard deviation of color values of the annotated pixels:\n",
      " [[14.39882563]\n",
      " [ 4.32889583]\n",
      " [ 7.2355212 ]]\n",
      "Covariance matrix of color values of the annotated pixels:\n",
      " [[207.33660837 -19.72096074  25.87952376]\n",
      " [-19.72096074  18.74028175   6.27398643]\n",
      " [ 25.87952376   6.27398643  52.35540042]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_true = cv2.imread('Output/1/1/CieLAB/Ground_true_EB-02-660_0594_0326.JPG')\n",
    "img = cv2.imread('Images/EB-02-660_0594_0326.JPG')\n",
    "\n",
    "# lower bound and upper bound for red color\n",
    "lower_bound = np.array([0, 0, 250])\n",
    "upper_bound = np.array([0, 0, 255])\n",
    "\n",
    "# Find the colors within the boundaries\n",
    "mask = cv2.inRange(img_true, lower_bound, upper_bound)\n",
    "cv2.imwrite(\"Output/1/1/CieLAB/mask.png\", mask)\n",
    "mask_pixels = np.reshape(mask, (-1))\n",
    "\n",
    "img = cv2.bitwise_and(img, img, mask=mask)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "pixels = np.reshape(img, (-1, 3))\n",
    "cv2.imwrite(\"Output/1/1/CieLAB/CieLAB.png\", img)\n",
    "\n",
    "# Mean and standard deviation\n",
    "mean, std = cv2.meanStdDev(img, mask=mask)\n",
    "print(f\"Mean color values of the annotated pixels:\\n {mean}\")\n",
    "print(f\"Standard deviation of color values of the annotated pixels:\\n {std}\")\n",
    "\n",
    "# Covariance\n",
    "cov = np.cov(pixels.transpose(), aweights=mask_pixels)\n",
    "print(f\"Covariance matrix of color values of the annotated pixels:\\n {cov}\")\n",
    "\n",
    "# Save the parameters\n",
    "np.savetxt(\"Output/1/1/CieLAB/lower.txt\", mean-std, delimiter=' ', fmt='%1.4f')\n",
    "np.savetxt(\"Output/1/1/CieLAB/upper.txt\", mean+std, delimiter=' ', fmt='%1.4f')\n",
    "np.savetxt(\"Output/1/1/CieLAB/mean.txt\", mean, delimiter=' ', fmt='%1.4f')\n",
    "\n",
    "# Test the output\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "mask = cv2.inRange(img, mean-std, mean+std)\n",
    "img_test = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite(\"Output/1/1/CieLAB/test.png\", img_test)\n",
    "\n",
    "# Show the histogram\n",
    "colors = ['b', 'g', 'r']\n",
    "for dim in range(img_test.ndim):\n",
    "    data = np.reshape(img_test[:, :, dim], (-1))\n",
    "    plt.hist(data[data != 0], bins=255, color=colors[dim], alpha=0.5)\n",
    "plt.savefig(\"Output/1/1/CieLAB/histogram.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1.2\n",
    "Segment the orange pumpkins from the background\n",
    "using color information. Experiment with the following segmentation methods\n",
    "1. inRange with RGB values\n",
    "2. inRange with CieLAB values\n",
    "3. Distance in RGB space to a reference colour\n",
    "4. (HLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Test RGB\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "lower_bound = np.loadtxt(\"Output/1/1/BGR/lower.txt\", delimiter=' ')\n",
    "upper_bound = np.loadtxt(\"Output/1/1/BGR/upper.txt\", delimiter=' ')\n",
    "mask = cv2.inRange(img, lower_bound, upper_bound)\n",
    "img_test = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite(\"Output/1/2/BGR.png\", img_test)\n",
    "\n",
    "# Test the output\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "lower_bound = np.loadtxt(f\"Output/1/1/CieLAB/lower.txt\", delimiter=' ')\n",
    "upper_bound = np.loadtxt(f\"Output/1/1/CieLAB/upper.txt\", delimiter=' ')\n",
    "mask = cv2.inRange(img, lower_bound, upper_bound)\n",
    "img_test = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imwrite(\"Output/1/2/CieLAB.png\", img_test)\n",
    "\n",
    "\n",
    "# Distance in RGB space to a reference color\n",
    "ref = np.loadtxt(f\"Output/1/1/BGR/mean.txt\", delimiter=' ')\n",
    "pixels = np.reshape(img, (-1, 3))\n",
    "cov = np.cov(pixels.transpose())\n",
    "diff = pixels - np.repeat([ref], np.ma.size(pixels,axis=0),axis=0)\n",
    "# Calculate the distances\n",
    "mahalanobis = np.sqrt(np.sum(np.dot(diff,np.linalg.inv(cov)) *diff , axis=1))  \n",
    "euclidian = np.sqrt(np.sum(diff * diff, axis=1))\n",
    "# Reshaping to image dimension\n",
    "mahalanobis_img = np.reshape(mahalanobis,(img.shape[0],img.shape[1]))\n",
    "euclidian_img = np.reshape(euclidian,(img.shape[0],img.shape[1]))\n",
    "# Scaling to 8 bit greyscale image\n",
    "scaled_mahalanobis_img = 255*mahalanobis_img/np.max(mahalanobis_img)\n",
    "scaled_euclidian_img = 255*euclidian_img/np.max(euclidian_img)\n",
    "# Saving scaled images\n",
    "cv2.imwrite(\"Output/1/2/euclidian_dist_map.png\", scaled_euclidian_img)\n",
    "cv2.imwrite(\"Output/1/2/mahalanobis_dist_map.png\", scaled_mahalanobis_img)\n",
    "\n",
    "# Setting up a threshhold for mahalanobis\n",
    "ret,threshold_img = cv2.threshold(scaled_mahalanobis_img,135,255, cv2.THRESH_BINARY_INV)\n",
    "threshold_img = threshold_img.astype(np.uint8)\n",
    "cv2.imwrite(\"Output/1/2/mahalanobis_segmented.png\", threshold_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1.3\n",
    "Choose one segmentation method to use for the rest\n",
    "of the mini-project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "BGR = \"BGR\"\n",
    "CieLAB = \"CieLAB\"\n",
    "\n",
    "def segmentation(img: np.ndarray, method: str = CieLAB) -> np.ndarray:\n",
    "    \"\"\"Segmentation of an image to find a color spectrum\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): Image used for segmentation\n",
    "        type (str, optional): Type of image used for segmentation. Defaults to BGR.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Image containing the orange color\n",
    "    \"\"\"\n",
    "\n",
    "    # Fetch the lower and upper bounds\n",
    "    lower_bound = np.loadtxt(f\"Output/1/1/{method}/lower.txt\", delimiter=' ')\n",
    "    upper_bound = np.loadtxt(f\"Output/1/1/{method}/upper.txt\", delimiter=' ')\n",
    "    ref = np.loadtxt(f\"Output/1/1/{method}/mean.txt\", delimiter=' ')\n",
    "    # TODO\n",
    "    ref = np.loadtxt(f\"Output/1/1/BGR/mean.txt\", delimiter=' ')\n",
    "\n",
    "    '''\n",
    "\n",
    "    # Copy the image\n",
    "    img_tmp = img.copy()\n",
    "\n",
    "    if method == CieLAB:\n",
    "        img_tmp = cv2.cvtColor(img_tmp, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    mask = cv2.inRange(img_tmp, lower_bound, upper_bound)\n",
    "    return cv2.bitwise_and(img_tmp, img_tmp, mask=mask)\n",
    "    '''\n",
    "\n",
    "    # Copy the image\n",
    "    img_tmp = img.copy()\n",
    "\n",
    "    if method == BGR:\n",
    "        lower_bound = np.loadtxt(\"Output/1/1/BGR/lower.txt\", delimiter=' ')\n",
    "        upper_bound = np.loadtxt(\"Output/1/1/BGR/upper.txt\", delimiter=' ')\n",
    "        mask = cv2.inRange(img_tmp, lower_bound, upper_bound)\n",
    "        img_test = cv2.bitwise_and(img_tmp, img_tmp, mask=mask)\n",
    "        return img_test\n",
    "    if method == CieLAB:\n",
    "        img_tmp = cv2.cvtColor(img_tmp, cv2.COLOR_BGR2LAB)\n",
    "        lower_bound = np.loadtxt(f\"Output/1/1/CieLAB/lower.txt\", delimiter=' ')\n",
    "        upper_bound = np.loadtxt(f\"Output/1/1/CieLAB/upper.txt\", delimiter=' ')\n",
    "        mask = cv2.inRange(img_tmp, lower_bound, upper_bound)\n",
    "        img_test = cv2.bitwise_and(img_tmp, img_tmp, mask=mask)\n",
    "\n",
    "\n",
    "    # Distance in RGB space to a reference color\n",
    "    pixels = np.reshape(img_tmp, (-1, 3))\n",
    "    cov = np.cov(pixels.transpose())\n",
    "    diff = pixels - np.repeat([ref], np.ma.size(pixels,axis=0),axis=0)\n",
    "    # Calculate the distances\n",
    "    mahalanobis = np.sqrt(np.sum(np.dot(diff,np.linalg.inv(cov)) *diff , axis=1))  \n",
    "    # Reshaping to image dimension\n",
    "    mahalanobis_img = np.reshape(mahalanobis,(img_tmp.shape[0],img_tmp.shape[1]))\n",
    "    # Scaling to 8 bit greyscale image\n",
    "    scaled_mahalanobis_img = 255*mahalanobis_img/np.max(mahalanobis_img)\n",
    "    \n",
    "    # Setting up a threshhold for mahalanobis\n",
    "    ret,threshold_img = cv2.threshold(scaled_mahalanobis_img,135,255, cv2.THRESH_BINARY_INV)\n",
    "    return threshold_img.astype(np.uint8)\n",
    "\n",
    "# Test the segmentation\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "img_test = segmentation(img, method=BGR)\n",
    "cv2.imwrite(\"Output/1/3/BGR.png\", img_test)\n",
    "img_test = segmentation(img, method= CieLAB)\n",
    "cv2.imwrite(\"Output/1/3/CieLAB.png\", img_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Counting objects\n",
    "This part is about counting objects in segmented\n",
    "images and then to generate some visual output that\n",
    "will help you to debug the programs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.1\n",
    "Count the number of orange blobs in the segmented\n",
    "image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number contours: 5378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "segmented = segmentation(img, method=CieLAB)\n",
    "contours, hierarchy = cv2.findContours(segmented, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get the width, height and position of each contour\n",
    "width = []\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    width.append(w)\n",
    "    cv2.circle(img, (x,y), 10, (0, 0, 255), 2)\n",
    "\n",
    "# Print histogram of size\n",
    "plt.figure()\n",
    "plt.hist(width,bins=255)\n",
    "plt.savefig(\"Output/2/1/histogram.png\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "print(f\"Number contours: {len(contours)}\")\n",
    "cv2.imwrite(\"Output/2/1/circle_pumpkins.png\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.2\n",
    "Filter the segmented image to remove noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "segmented = segmentation(img, method=CieLAB)\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "# Opening\n",
    "filtered = cv2.erode(segmented, kernel, iterations=1)\n",
    "filtered = cv2.dilate(filtered, kernel, iterations=1)\n",
    "cv2.imwrite(\"Output/2/2/filtered.png\", filtered)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.3\n",
    "Count the number of orange blobs in the filtered image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number contours: 2527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('Images/EB-02-660_0594_0344.JPG')\n",
    "filtered = cv2.imread('Output/2/2/filtered.png')\n",
    "filtered = cv2.cvtColor(filtered, cv2.COLOR_BGR2GRAY)\n",
    "contours, hierarchy = cv2.findContours(filtered, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Get the width, height and position of each contour\n",
    "width = []\n",
    "for c in contours:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    width.append(w)\n",
    "    cv2.circle(img, (x,y), 10, (0, 0, 255), 2)\n",
    "\n",
    "# Print histogram of size\n",
    "plt.figure()\n",
    "plt.hist(width,bins=255)\n",
    "plt.savefig(\"Output/2/3/histogram.png\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"Number contours: {len(contours)}\")\n",
    "cv2.imwrite(\"Output/2/3/circle_pumpkins.png\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.2.4\n",
    "Mark the located pumpkins in the input image. This\n",
    "step is for debugging purposes and to convince others\n",
    "that you have counted the pumpkins accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Generate an orthomosaic\n",
    "This part deals with orthorectifying multiple images\n",
    "of the same field into a single carthometric product.\n",
    "Choose proper settings for all below processes, taking into consideration the available computing resources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.1\n",
    "Load data into Metashape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.2\n",
    "Perform bundle adjustment (align photos) and check\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.3\n",
    "Perform dense reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.4\n",
    "Create digital elevation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.5\n",
    "Create orthomosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.3.6\n",
    "Limit orthomosaic to pumpkin field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Count in orthomosaic\n",
    "Use the python package rasterio to perform operations on the orthomosaic using a tile based approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.1\n",
    "Create code that only loads parts of the orthomosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.2\n",
    "Design tile placement incl. overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.3\n",
    "Count pumpkins in each tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.4\n",
    "Deal with pumpkins in the overlap, so they are only\n",
    "counted once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.4.5\n",
    "Determine amount of pumpkins in the entire field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5 Endnotes\n",
    "Reflect on the conducted work in this miniproject."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5.1\n",
    "Determine GSD and size of the image field. What is\n",
    "the average number of pumpkins per area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.5.2\n",
    "Reflect on whether the developed system is ready to\n",
    "help a farmer with the task of estimating the number\n",
    "of pumpkins in a field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
